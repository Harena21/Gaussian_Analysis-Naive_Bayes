{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e424e4",
   "metadata": {},
   "source": [
    "## DO NOT USE FOR LOOP ON number of samples N but ONLY ON number of classes C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a4b0d2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5b3a9bb5f9459df46861b5d84bda38",
     "grade": false,
     "grade_id": "cell-f4572dec0c7469a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits, load_digits\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39598113",
   "metadata": {},
   "source": [
    "# Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7b03949",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19e957d3826dd3977f54f428a8744d6",
     "grade": false,
     "grade_id": "cell-d82471ddcebf7ede",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X_train, y_train = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "596068c6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5735812b7d43eb37d2bd53c84670597",
     "grade": false,
     "grade_id": "cell-212a715c4b2f4e77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_priors(X, y):\n",
    "    \"\"\"\n",
    "    Prior probability for each class \n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - priors : array of shape (C,)\n",
    "    \"\"\"\n",
    "    C = (np.max(y) + 1)\n",
    "    priors = np.zeros(C)\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(C):\n",
    "        priors[i] = sum(y[y==i].shape)/y.shape[0]\n",
    "    \n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2dc84667",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4595f1d0682daf1d642222e34ca7546f",
     "grade": true,
     "grade_id": "cell-25707d195d3be37b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "priors = compute_priors(X_train, y_train)\n",
    "error = rel_error(sk_model.priors_, priors)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26d5036a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80987a776d96e04af5c7a0922be6fc7b",
     "grade": false,
     "grade_id": "cell-a4f5a8d209b51a14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_means(X, y):\n",
    "    \"\"\"\n",
    "    Mean estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - means : array of shape (C, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    means = np.zeros((C, D))\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(C):\n",
    "        indices_of_rows = np.where(np.isin(y,i))\n",
    "        X_subset = X[indices_of_rows]\n",
    "        \n",
    "        means[i] = (np.sum(X_subset,axis=0) / float(len(X_subset)))\n",
    "        \n",
    "    return means\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d39aebd0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5139bd849307229ab94c6dc869516b",
     "grade": true,
     "grade_id": "cell-1ea0c5a7199f1d21",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "means = compute_means(X_train, y_train)\n",
    "error = rel_error(sk_model.means_, means)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1e81de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cov(rows,mean):\n",
    " #   return (rows.reshape(-1,1)-mean).dot((rows.reshape(-1,1)-mean).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83f43ffa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d440cdafa2d4b166c5220793a35fcf7",
     "grade": false,
     "grade_id": "cell-f1401a628db797ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigmas_gda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariances : array of shape (C, D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariances = np.zeros((C, D, D))\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(C):\n",
    "        indices_of_rows = np.where(np.isin(y,i))\n",
    "        X_subset = X[indices_of_rows]\n",
    "        covariances[i] = (1./(X_subset.shape[0]-1)) * ((X_subset - means[i]).T@(X_subset - means[i]))\n",
    "    \n",
    "    return covariances;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc5a7f7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a27ecc6bbc72e72cfebaffd3ede565",
     "grade": true,
     "grade_id": "cell-6b136fdb522b6eff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.920351755031412e-16\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigmas_gda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbcf24c0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "824613ff0ad0e3acb8e67b499598fbba",
     "grade": false,
     "grade_id": "cell-9970ad744b99041a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigma_lda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for LDA, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariance : array of shape (D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariance = np.zeros((D, D))\n",
    "    # YOUR CODE HERE\n",
    "    means = compute_means(X_train,y_train)\n",
    "\n",
    "    for i in range(C):\n",
    "        X_subset = X[y==i]\n",
    "        covariance += (X_subset.shape[0]-1)*covariances[i]\n",
    "    \n",
    "    return covariance/N;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0e4bfa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a95472e963297e49709fc0b8c212e341",
     "grade": true,
     "grade_id": "cell-686b35c7c584416e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.453612124347883e-17\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigma_lda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f84312aa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b0c0ed8697c9ae414131f3918c0037",
     "grade": false,
     "grade_id": "cell-17c0ce2515e2fc7c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_lda(X, C, priors, means, covariance):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariance : array of shape (D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    W = np.zeros((C,D))\n",
    "    b = np.zeros(C)\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(C):\n",
    "        log_posterior[:,i]= np.diag(np.log(priors[i]) - (1/2)*np.log(np.linalg.det(covariance)) - (1/2)*( (X-means[i])@np.linalg.inv(covariance)@ (X-means[i]).T )) \n",
    "        \n",
    "    return log_posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ddec807",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bb8777a126866cace4cb4d1b73225f5",
     "grade": false,
     "grade_id": "cell-7a43326dd032e8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NO TEST FOR LOG-POSTERIOR LDA. Mitambatra eo ambany ny test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9e2a8ee0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2ed41a12624f40c8eabd8a1bac44cb4",
     "grade": false,
     "grade_id": "cell-cc5e3a7eddeb02ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_gda(X, C, priors, means, covariances):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariances : array of shape (C, D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(C):\n",
    "        log_posterior[:,i]= np.diag(np.log(priors[i]) - (1/2)*np.log(np.linalg.det(covariances[i])) - (1/2)*( (X-means[i])@np.linalg.inv(covariances[i])@ (X-means[i]).T ) )\n",
    "        \n",
    "    return log_posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8c38e381",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c0afab4af1700e0a0fc48dd1118bdd",
     "grade": true,
     "grade_id": "cell-d58bf74c60153098",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.605541792973586e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "C = (np.max(y_train) + 1)\n",
    "log_posterior = compute_log_posterior_gda(X_train, C, sk_model.priors_, sk_model.means_, sk_model.covariance_)\n",
    "error = rel_error(np.asarray(sk_model._decision_function(X_train)), log_posterior)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9de0226f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea4a371e372fa034dcbf73d579c3358",
     "grade": false,
     "grade_id": "cell-f5cbad4c325e856e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbClassifier():\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        # YOUR CODE HERE\n",
    "        return np.argmax(log_post,axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        # YOUR CODE HERE\n",
    "        N = np.exp(log_post).sum(axis=1).shape[0]\n",
    "        \n",
    "        return np.exp(log_post)/np.exp(log_post).sum(axis=1).reshape((N,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00619c96",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c234be9d70fd14a4551b6fcbf8de7ea5",
     "grade": false,
     "grade_id": "cell-1bbbe43fcaed8c4e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigma_lda(X, y, self.means)\n",
    "        #raise NotImplementedError()\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        return compute_log_posterior_lda(X, self.C, self.priors, self.means, self.cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bad71564",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "470a4776ad0f7dd0fa6df62af2985724",
     "grade": true,
     "grade_id": "cell-103960c9425d1e47",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-95-eb4606b1b2e9>:26: RuntimeWarning: divide by zero encountered in log\n",
      "  b= (1/2)*np.log(np.linalg.det(covariance))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-8d98fd8de36a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msk_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-1cef41c4a37d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlog_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_log_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_post\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-ac60011016e5>\u001b[0m in \u001b[0;36mcompute_log_posterior\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_log_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_log_posterior_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-eb4606b1b2e9>\u001b[0m in \u001b[0;36mcompute_log_posterior_lda\u001b[0;34m(X, C, priors, means, covariance)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlog_posterior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlog_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_posterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "pred = lda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca8c6e3b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c02ef4c722a12c047cdd79a33b701bf",
     "grade": false,
     "grade_id": "cell-a86acf06e6c80728",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class QDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigmas_gda(X, y, self.means)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        return compute_log_posterior_gda(X, self.C, self.priors, self.means, self.cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eaceff8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e49782d08f05716006eaa10b9483f",
     "grade": true,
     "grade_id": "cell-407cb9988a114256",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e74ae0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7666654f5e7cfcd44a8c2dc0291c0ed9",
     "grade": true,
     "grade_id": "cell-1d95b01b2541d240",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.111122555721264e-15\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict_proba(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict_proba(X_train)\n",
    "\n",
    "error = rel_error(pred, sk_pred)\n",
    "print(error)\n",
    "assert error < 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17af43",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2639cfb",
   "metadata": {},
   "source": [
    "##  Bernouilli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87252e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X_train2, y_train2 = data.data, data.target\n",
    "X_train2_transf = Binarizer().fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "04021ee0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70742cc3e580d8bfdbf0b9de07a87912",
     "grade": false,
     "grade_id": "cell-d5b51da0e0b8dcc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BernouilliNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.theta = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameter theta\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.theta = np.zeros((D, self.C,))\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = np.zeros((self.C))\n",
    "        for i in range(self.C):\n",
    "            X_subset = X[y==i]\n",
    "            Ni = X_subset.shape[0]\n",
    "            self.priors[i] = Ni/N\n",
    "            self.theta[:,i] = np.sum(X_subset,axis=0)/Ni\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        eps = 1e-11\n",
    "        log_post = (X @ np.log(self.theta + eps)) + ((1-X) @ np.log(1-self.theta + eps)) + np.log(self.priors)\n",
    "        \n",
    "        return log_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a70e61a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa098602d1a9e4c9cdca9cf73180a44",
     "grade": true,
     "grade_id": "cell-f960b1ec2ce34b3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.8636616583194212\n",
      "Your Accuracy :  0.8742348358375069\n"
     ]
    }
   ],
   "source": [
    "sk_model = BernoulliNB()\n",
    "sk_model.fit(X_train2_transf, y_train2)\n",
    "sk_pred = sk_model.predict(X_train2_transf)\n",
    "\n",
    "model = BernouilliNaiveBayes()\n",
    "model.fit(X_train2_transf, y_train2)\n",
    "pred = model.predict(X_train2_transf)\n",
    "\n",
    "sk_acc = accuracy_score(y_train2, sk_pred)\n",
    "model_acc = accuracy_score(y_train2, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d8dc6",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "99588c0d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d67f1b1383503b5e5203c265f59b99d",
     "grade": false,
     "grade_id": "cell-186f17a680895047",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.mu = None\n",
    "        self.sigma = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameters mu and sigma\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.sigma = np.zeros((D, self.C))\n",
    "        self.mu = np.zeros((D,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        self.priors = np.zeros(self.C)\n",
    "        for i in range(self.C):\n",
    "            Ni = np.sum(y==i)\n",
    "            self.priors[i] = Ni/N\n",
    "            self.mu[:,i] = np.sum(X[y==i],axis=0)/Ni\n",
    "            self.sigma[:,i] =  np.sum((1/Ni)*(X[y==i] - (np.sum(X[y==i], axis=0)/Ni))**2, axis=0)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        for j in range(self.C):\n",
    "            log_post[:, j] = np.log(self.priors[j]) + -(1/2)*np.sum(np.log(2*np.pi* self.sigma[:,j].T)+((X - self.mu[:,j].T)**2)/self.sigma[:,j].T, axis=1)\n",
    "        \n",
    "        return log_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2072fea0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d510e4b6069f1d0549606f4a4a12416",
     "grade": true,
     "grade_id": "cell-7ac37952b1e80482",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.96\n",
      "Your Accuracy :  0.96\n"
     ]
    }
   ],
   "source": [
    "sk_model = GaussianNB()\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "model = GaussianNaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_train)\n",
    "\n",
    "sk_acc = accuracy_score(y_train, sk_pred)\n",
    "model_acc = accuracy_score(y_train, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ebeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
